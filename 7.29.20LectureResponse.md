### Using NLP to build a sarcasm classifier
#### Question One: Pick two or three news sources and select a few news titles from their feed (about 5 is likely enough). Run your sarcasm model to predict whether the titles are interpreted as sarcastic or not.  Analyze the results and comment on the different news sources you have selected.

**The Onion Headlines:** "Toddler Feels Somewhat Torn About Pretending To Te A Policman in Current Climate" , "More Cities Offering Drive-Thru Covid Injection Sites To Put Citizens Out of Misery" , "Closed Ballpark Forces Thousands of of Phillies Fans To Be Content Verbally Threatening Friends and Family" , "Queen Elizabeth II Worried She's Next On The Chopping Block If Beefeaters Laid Off" , "Defensive Chicago Police Officer Perfectly Capable Of Diasappearing Protestors Without Help From Homeland Security"

**Scores:** 0.58188504, 0.9894364, 0.9989072,0.96631986, 0.9884687
**Sum:** 4.5250172
**Average:** 0.90500344

**LeMonde Headlines:** "It’s the healthcare system, stupid" , "The meritocrats shall inherit the earth" , "Where are the Women Peacemakers" , "Saudi Arabia's Holy Business" , "The US's new evil empire"

**Scores:** 0.10120084, 0.00018812, 0.00015933, 0.02182123, 0.17829928
**Sum:** 0.3016688
**Average:** 0.06033376

**AP News Headlines:** "4 Big Tech CEOs getting heat from Congress on competition" , "Trump dismisses virus aid for cities, lashes out at GOP" , "Early in pandemic frantic doctors traded tips across oceans" , "As crime surges on his watch, Trump warns of Biden's America" , "Garth Brooks doesn't want to win CMA entertainer award again"

**Scores:** 0.00668844, 2.9093371e-06, 0.74666834, 2.7510084e-06, 0.25262085
**Sum:** 1.0059832903455002
**Average:** 0.20119665806910003

| News Source      | Average Sarcasm Score  |
| ------------|:-------------:|
| The Onion     |  0.905      |  
| LeMonde     | 0.060       |  
| AP News    | 0.201      |              
 

For my news sources I decided to test out the Onion (which I known to be highly satirical), LeMonde (A french news site that is meant for a general audeince and is widely read) and AP News (which is touted as one of the least biased/most reliable news outlets). I thought this list of news sources would give me a good range to test fro my model and the model predictions lined up largely with what I was expecting; The onion had an average score of .90 which is very close to 1 ( a score closer to 1 in this case meant more sarcastic, whereas a score closer to 0 meant less sarcastic), and I think it is clear from the titles that it is, in fact, a very sarcastic source. The AP News headlings had an average score of .20 which is inline with it being a very serious, well-regarded news outlet. LeMonde was a bit of a suprise for me. It had an average score of .06, which was less than that of AP News. LeMonde had (at least in my opinon) a few sarcastic sentences in the bunch of headlines that I chose (for example: "It’s the healthcare system, stupid") and yet the model thought that LeMonde's headlines were less sarcastic than the AP News headlines which were literally just statements of facts.   

### Text generation with an RNN
#### Question One: Use the generate_text() command at the end of the exercise to produce synthetic output from your RNN model. Run it a second time and review the output. How has your RNN model been able to “learn” and “remember” the shakespeare text in order to reproduce a similar output?

#### Question Two (Stretch goal): replace the Shakespeare text with your own selected text and run the model again.  Modify the source text as needed in order to generate_text() from the newly trained model.

### Neural machine translation with attention

#### Question One: Use the translate() command at the end of the exercise to translate three sentences from Spanish to English.  How did your translations turn out? 

#### Question Two (Stretch goal): pick a scene from a movie that is acted out in a language other than English.  Download the appropriate language dataset and translate the scene.  How did your translation turn out this time? 
