### Problem Statement 

### Describe your implementation of the cats & dogs exercise. How did you setup the data?

####  Question One: Which optimizer have you selected, and how might it compare to other possible choices?  
For this lab I used the RMSprop optimizer. . Rprop combines the idea of only using the sign of the gradient with the idea of adapting the step size individually for each weight. step size adapts individually over time, so that we accelerate learning in the direction that we need. To adjust the step size for some weight, the following algorithm is used:
First, we look at the signs of the last two gradients for the weight.
If they have the same sign, that means, we’re going in the right direction, and should accelerate it by a small fraction, meaning we should increase the step size multiplicatively 
Rprop is equivalent of using the gradient but also dividing by the size of the gradient, so we get the same magnitude no matter how big a small that particular gradient is.
The problem with mini-batches is that we divide by different gradient every time, so why not force the number we divide by to be similar for adjacent mini-batches. The central idea of RMSprop is keep the moving average of the squared gradients for each weight
#### Question two: .Describe your selected loss function and it’s implementation. How is it effectively penalizing bad predictions? 
loss='binary_crossentropy',
If we fit a model to perform this classification, it will predict a probability of being green to each one of our points. Given what we know about the color of the points, how can we evaluate how good (or bad) are the predicted probabilities? This is the whole purpose of the loss function! It should return high values for bad predictions and low values for good predictions.
The bars represent the predicted probabilities associated with the corresponding true class of each point!
Since we’re trying to compute a loss, we need to penalize bad predictions, right? If the probability associated with the true class is 1.0, we need its loss to be zero. take the (negative) log of the probabilities . compute the mean of all these losses
we can compute the entropy (uncertainty) of a distribution
#### Question 3: What is the purpose of the metric= argument in your model.compile() function?
metrics=['acc'] it is meant to judge the performance of the model, but the results arent used for training the mode

#### Question 4: Plot the accuracy and loss results for both the training and test datasets.  Include these in your response.  Assess the model and describe how good you think it performed.
![validationaccuracy](https://user-images.githubusercontent.com/67922294/87975622-dd4f7300-ca99-11ea-8d50-a6bdc8c80f90.png)

#### Question five: Use the model to predict 3 dog images and 3 cat images.  Upload you images and the prediction.  How did your model perform in practice?  Do you have any ideas of how to improve the model’s performance?
![catsdogs](https://user-images.githubusercontent.com/67922294/87971666-aece9980-ca93-11ea-960a-12e7dec3ebc1.png)
