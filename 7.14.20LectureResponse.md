### Last week you did an exercise where you manually applied a 3x3 array as a filter to an image of two people ascending an outdoor staircase.  Modify the existing filter and if needed the associated weight in order to apply your new filters to the image 3 times.  Plot each result, upload them to your response, and describe how each filter transformed the existing image as it convolved through the original array and reduced the object size. What are you functionally accomplishing as you apply the filter to your original array?  Why is the application of a convolving filter to an image useful for computer vision? 

![filter1](https://user-images.githubusercontent.com/67922294/87457695-cd85e980-c5d6-11ea-8442-66784806ddf7.png)
1. filter = [ [0, 1, 0], [1, -4, 1], [0, 1, 0]], weight = 1

This image very faintly pulled out the vertical lines along the left-hand and right-hand sides of the image. The lines in the middle of the image all but disappeared and this may be because the fiter multiplied the values of the pixels in the middle of each bunch of pixels by -4 thereby highlighting the edges of the features in the image.  


![filter2](https://user-images.githubusercontent.com/67922294/87458122-7b919380-c5d7-11ea-8e2e-ba603fb4ee97.png)
2. filter = [ [-1, 0, 1], [-2, 0, 2], [-1, 0, 1]], weight = 1

This image pulled out the vertical lines in the image and make them really stand out. 

![filter3](https://user-images.githubusercontent.com/67922294/87458244-b3004000-c5d7-11ea-931f-e01ee8bd28ec.png)

3. fliter = [ [1, 1, 1], [1, 2, 1], [1, 1, 1]], weight = .1

This image essentially just returned the original image to me. I beleive this is because the filter was so evenly spread out and the changes applied across the bunch of pixels were well-balanced and minimal at best, so very little was actually being changed. 

We are essentially convulving these images. A convolution is a filter that passes over an image, processes it and then extracts features that show a commonolatity in the image. The way that a convolution works is it scans every pixel in the image and then looks at it's neighboring pixels. Then the value of each pixel is multiplied by the equivalent weight in a filter to help identify features/commonalities in the image.This ability to extract commonalities in images is what makes a convolving filter image so useful for computer vision; by allowing the computer to pick up on commonalities, the computer has more flexibility/ lee-way in terms of identifying features in images. With convulving filters, the computer no longer is just looking at the raw pixels of an image but is now able to identify the actual features that make up an object, so there is more flexibility in terms of correctly identifying objects no matter what form/perspective they show up in. 

### B.Another useful method is pooling.  Apply a 2x2 filter to one of your convolved images, and plot the result.  In effect what have you accomplished by applying this filter?  Can you determine from the code which type of pooling filter is applied, and the method for selecting a pixel value?  Did the result increase in size or decrease?  Why would this method be better? 

![pooling](https://user-images.githubusercontent.com/67922294/87459848-ee037300-c5d9-11ea-81a9-1c2b6341aa01.png)

Essentially, after pooling my image with a 2x2 filter the horizontal and vertical lines now appear to stand out more than in the original image. In this case it seems that the MaxPooling filter has been applied. MaxPooling takes blocks of pixels (in this case, it took a block that was 2 blocks by 2 blocks, or four total pixels) and pulls out only the pixels with the biggest values. This allows the computer to pull out important features and get rid of extraneous information.


### C.The lecture for today (Coding with Convolutional Neural Network) compared the application of our previously specified deep neural network with a newly specified convolutional neural network.  Instead of using the fashion_MNIST dataset, use the mnist dataset (the hand written letters) to train and compare your DNN and CNN output.      Were you able to improve your model by adding the Conv2D and MaxPooling2D layers to your neural network?  Plot the convolutions graphically, include them in your response and describe them.  Edit the convolutions be changing the 32s to either 16 or 64 and describe what impact this had on accuracy and training time.  What happens if you add more convolution layers?

Using a CNN increased my accuracy for the mnist dataset; the accuracy was already pretty high with the DNN (about 97%) but with the CNN my accuracy was a bit higher at nearly 100%. 

![convolutions](https://user-images.githubusercontent.com/67922294/87829034-27dbb000-c84c-11ea-9a8d-6e97efaa0e7c.png)

You can see in the plot above that as the images are convolved the computer begins to pull out common features in each number. For example, with the number seven the horizontal line at the top of the image and the vertical line extending from this horizontal line are pulled out and highlighted which helps the computer mark this number as a seven, with each convultion a part of a defining feature of a number is pulled out adn then in the next round this feature is built on until a number can be identified from the highlighted features. As I changed the 32s to 64s, the accuracy and training time increased, whereas when I changed the 32s to 16s the accuracy and training time both decreased. Furthermore, as I added more convolutin layers both the accuracy and training time increased.
