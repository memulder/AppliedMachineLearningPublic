I modeled my project off of the linear regression tensorflow exercise that we did earlier in the class as the goal of this project was to predict a continuous value (i.e population). I created a simple DNN with three dense layers of 128, 64, and 1 neurons. The fact that this was a regression problem informed all of the decisions I made when I was compiling my model. For my loss function I decided to use MSE because MSE is good for regression problems. For my optimizer I decided to use Adam. I was initially going to use RMSprop because it has such a fast learning rate, but I did some reading on optimizers and it seemed like Adam would take the best parts of RMSprop and another technique (Momentum) and combine them, which I thought would be best for my model. I used 0.001 as my learning rate just to get things started because initially I had no idea what a good learning rate would be. Finally, when compiling my model I decided the metrics that would best indicate how well my model was working were MAE and MSE as MAE (Mean absolute error) could tell me the average difference observed in the predicted and actual values across the whole data set (a lower score is better) and MSE (Mean Squared Error) would tell me what the average squared difference between the estimated values and the actual values for the data set.

I initially went with a very small model that was modeled off of the basic regression model from the tensorflow exercise. Again, because this was a regression problem I used a reLu activation, especailly since I wanted my numerical output (i.e the population prediction) to be a positive number. On the very first run I only trained my model on 50 images with 5 epochs, a batch size of 5 and 10 steps per epoch. The results were...  I slowly bumped up each argument until I was able to train my computer on 1000 images, with 20 epochs, a batch size of 20 and 30 steps per epoch, I also included a validation split of 0.2, which resulted in a loss of 228.5554, a mae of 12.4009, a mse of 228.5554 and   a validation loss of 197.3452, a validation mae of 9.9374 , and a validation mse of 197.3452. For the test images the loss was 7131.8188 the mae was 75.8363 and the mse was 7131.8188.

![P3MSE](https://user-images.githubusercontent.com/67922294/88489194-e8eede00-cf60-11ea-9dab-8c8ca76db58c.png)


To predict the population values I used 

This was actually a very useful project for me. After first I was overwhelmed by the openness of the instructions but it caused me to realize that while I was understanding each individual component of the model that we were learning through the tensforflow exercises, I was not understanding how all of these components fit together and what the metrics my models were producing really meant. This project forced me to go back and really connect all of the dots and dig a little bit deeper. 
